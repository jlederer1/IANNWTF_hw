{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Mitx1jtKu1tl3S6MfrtWhRqpqcLT37u1","authorship_tag":"ABX9TyPCB5wuWTOLoo0pmKN2PKiK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4b1a9d5aa91141b59bab2c134f82d1bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5079fa6f6fbc434ea49ab13ea0979b92","IPY_MODEL_1981670e6a674338979b0283bbcbb475","IPY_MODEL_761947246c3a47cd8c741e8a64f47506"],"layout":"IPY_MODEL_92017abe02d9462c9bb6c44a6a2cdd7a"}},"5079fa6f6fbc434ea49ab13ea0979b92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af9a2794938f4e57a0a72d58e9a008b2","placeholder":"​","style":"IPY_MODEL_65e04b264e064c76920d0e49ab252760","value":"Dl Completed...: 100%"}},"1981670e6a674338979b0283bbcbb475":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57c97424f514451d85d911a214cd6cf1","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f7a2cb5722543aea1d029d90f04a640","value":4}},"761947246c3a47cd8c741e8a64f47506":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9bd4f3dc40c43c498c29569eecc1707","placeholder":"​","style":"IPY_MODEL_6894d5f7b9724b989ce5103e38c65be9","value":" 4/4 [00:00&lt;00:00, 11.33 file/s]"}},"92017abe02d9462c9bb6c44a6a2cdd7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9a2794938f4e57a0a72d58e9a008b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e04b264e064c76920d0e49ab252760":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57c97424f514451d85d911a214cd6cf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7a2cb5722543aea1d029d90f04a640":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9bd4f3dc40c43c498c29569eecc1707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6894d5f7b9724b989ce5103e38c65be9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"GugGz9W-oT1n","executionInfo":{"status":"ok","timestamp":1669669639022,"user_tz":-60,"elapsed":7528,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}},"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["4b1a9d5aa91141b59bab2c134f82d1bd","5079fa6f6fbc434ea49ab13ea0979b92","1981670e6a674338979b0283bbcbb475","761947246c3a47cd8c741e8a64f47506","92017abe02d9462c9bb6c44a6a2cdd7a","af9a2794938f4e57a0a72d58e9a008b2","65e04b264e064c76920d0e49ab252760","57c97424f514451d85d911a214cd6cf1","4f7a2cb5722543aea1d029d90f04a640","a9bd4f3dc40c43c498c29569eecc1707","6894d5f7b9724b989ce5103e38c65be9"]},"outputId":"4e1ef50e-f16f-40ca-8677-d668fd57b454"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ~/tensorflow_datasets/mnist/3.0.1...\n"]},{"output_type":"display_data","data":{"text/plain":["Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b1a9d5aa91141b59bab2c134f82d1bd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset mnist downloaded and prepared to ~/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"]}],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import numpy as np\n","import datetime\n","\n","#1. get mnist from tensorflow_datasets\n","mnist, info = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True, with_info=True)\n","ds_train = mnist[0]\n","ds_val = mnist[1]\n","\n","# print(info)\n","# tfds.show_examples(train, info) "]},{"cell_type":"code","source":["#2. write function to create the dataset that we want\n","def preprocess(data, batch_size) :\n","    #Image should be float\n","    data = data.map(lambda x, t: (tf.cast(x, tf.float32), tf.cast(t, tf.float32)))\n","    #Image should be flattened\n","    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n","    #Image vector will here have values between -1 and 1\n","    data = data.map(lambda x, t: ((x/128.)-1., t))\n","    #We want to have two mnist images in each example\n","    #This leads to a single example being ((x1,y1),(x2,y2))\n","    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n","                                     data.shuffle(2000)))\n","    \n","    #Map ((x1,y1),(x2,y2)) to ( x1, x2, t1 - t2, ((t1 + t2) >= 5) ) (*boolean and int)\n","    zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] - x2[1], (x1[1] + x2[1] >= 5) ))\n","    #Transform boolean target to int\n","    zipped_ds = zipped_ds.map(lambda x1, x2, t1, t2: (x1, x2, tf.cast(t1, tf.int32), tf.cast(t2, tf.int32) ))\n","    #Batch the dataset\n","    zipped_ds = zipped_ds.batch(batch_size)\n","    #Prefetch\n","    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n","    return zipped_ds\n","\n","train = preprocess(ds_train, batch_size=32) #ds_train.apply(preprocess)\n","val = preprocess(ds_val, batch_size=32) #ds_val.apply(preprocess)\n","\n","# check the contents of the dataset\n","for img1, img2, label_1, label_2 in train:\n","    print(img1.shape, img2.shape, label_1.shape, label_2.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh9vxA87o7g3","executionInfo":{"status":"ok","timestamp":1669672689959,"user_tz":-60,"elapsed":1141,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}},"outputId":"f911a3f7-1867-47c1-9f36-3722b53c0509"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 784) (32, 784) (32,) (32,)\n"]}]},{"cell_type":"code","source":["from tensorflow.python.util import tf_inspect\n","class MNISTCalc(tf.keras.Model) :\n","  ## 1. constructor\n","  def __init__(self) :\n","    super().__init__()\n","\n","    ## optimizer, loss function and metrics\n","    self.metrics_list = [ tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Mean(name=\"loss\") ]\n","    self.optimizer = tf.keras.optimizers.get(\"Adam\")\n","    self.loss_function_0 = tf.keras.losses.BinaryCrossentropy()\n","    self.loss_function_1 = tf.keras.losses.MeanSquaredError()\n","\n","    ## layers to encode the images (both layers used for both images)\n","    self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n","    self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n","    self.dense3 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n","    self.out_layer = tf.keras.layers.Dense(1,activation=tf.nn.softmax)\n","\n","    self.calc_1 = tf.keras.layers.Dense(1)\n","    self.calc_2 = tf.keras.layers.Dense(1,activation=tf.nn.sigmoid) \n","\n","  \n","  ## 2.1 call method (forward computation for mnist image classification)\n","  # @tf.function\n","  def classify(self, img) :\n","    img = self.dense1(img)\n","    img = self.dense2(img)\n","    img = self.dense3(img)\n","    output = self.out_layer(img)\n","    return output\n","\n","\n","  ## 2.2 call method (forward computation)\n","  @tf.function\n","  def call(self, imgs, training=False) :\n","    im_0, im_1 = imgs\n","    im_0 = self.classify(im_0)\n","    im_1 = self.classify(im_1)\n","\n","    imgs = tf.concat([im_0, im_1], axis=1)\n","    result_1 = self.calc_1(imgs)\n","    result_2 = self.calc_2(imgs)\n","\n","    ## Two output activations for respective tasks\n","    return result_1, result_2\n","\n","  ## 3. metrics property\n","  @ property\n","  def metrics(self):\n","    ## return a list with all metrics in the model\n","    return self.metrics_list\n","\n","  def reset_metrics(self):\n","    for metric in self.metrics:\n","      metric.reset_state()\n","\n","  ## 5. train step method\n","  @tf.function\n","  def train_step(self, data):\n","    img_0, img_1, label_0, label_1 = data\n","    with tf.GradientTape() as tape:\n","      output_0, output_1 = self((img_0, img_1), training=True)\n","      loss_0 = self.loss_function_0(label_0, output_0)\n","      loss_1 = self.loss_function_1(label_1, output_1)\n","      loss = loss_0 + loss_1\n","        \n","    gradients = tape.gradient(loss, self.trainable_variables)\n","    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","    \n","    ## update the state of the metrics according to loss\n","    self.metrics[0].update_state(label_0, output_0)\n","    self.metrics[1].update_state(loss)\n","    ## return a dictionary with metric names as keys and metric results as values\n","    return {m.name : m.result() for m in self.metrics}\n","\n","    ## 6. test_step method\n","    @tf.function\n","    def test_step(self, data):\n","      img_0, img_1, label_0, label_1 = data\n","      ## same as train step (without parameter updates)\n","      output_0, output_1 = self((img_0, img_1), training=False)\n","      loss_0 = self.loss_function_0(label_0, output_0)\n","      loss_1 = self.loss_function_1(label_1, output_1)\n","      loss = loss_0 + loss_2\n","\n","      self.metrics[0].update_state(label_0, output_0)\n","      self.metrics[1].update_state(loss)\n","      return {m.name : m.result() for m in self.metrics}"],"metadata":{"id":"VvR7CAo5qetN","executionInfo":{"status":"ok","timestamp":1669672691528,"user_tz":-60,"elapsed":282,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import datetime\n","def create_summary_writers(config_name):\n","    \n","    # Define where to save the logs\n","    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n","    # alternatively make a copy of the code that is used for later reference\n","    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n","    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n","\n","    # log writer for training metrics\n","    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n","    # log writer for validation metrics\n","    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n","    return train_summary_writer, val_summary_writer\n","\n","train_summary_writer, val_summary_writer = create_summary_writers(config_name=\"RUN1\")"],"metadata":{"id":"jtQ34Hhmcx2L","executionInfo":{"status":"ok","timestamp":1669674048159,"user_tz":-60,"elapsed":245,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import pprint\n","import tqdm\n","\n","def training_loop(model, optimizer, n_epochs, train, test, train_summary_writer, val_summary_writer, save_path) :\n","\n","  for e in range(n_epochs) :\n","    print(f\"Epoch {e}:\")\n","\n","    for batch in tqdm.tqdm(train, position=0, leave=True):\n","      metrics = model.train_step(batch)\n","      \n","      # logging the validation metrics to the log file which is used by tensorboard\n","      with train_summary_writer.as_default():\n","        for metric in model.metrics:\n","          tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n","\n","    print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n","    \n","    # 4. reset metric objects\n","    model.reset_metrics()\n","\n","    # 5. evaluate on validation data\n","    for batch in test:\n","      metrics = model.test_step(batch)\n","      # 6. log validation metrics\n","      with val_summary_writer.as_default():\n","          # for scalar metrics:\n","          for metric in model.metrics:\n","                  tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n","        \n","    print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n","    # 7. reset metric objects\n","    model.reset_metrics()\n","\n","  # 8. save model weights if save_path is given\n","  if save_path:\n","    model.save_weights(save_path)\n","  \n","\n","\n","  #####################################################################\n","  # if (task == \"regression\") :\n","  #   pass\n","  # elif (task == \"classification\") :\n","  #   pass"],"metadata":{"id":"LPTnViswTa2D","executionInfo":{"status":"ok","timestamp":1669674137227,"user_tz":-60,"elapsed":236,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def training(optimizers, n_epochs, task = \"calc\") :\n","  calculator = MNISTCalc()\n","  empty_imgs = (np.zeros((1, 28**2)), np.zeros((1, 28**2)))\n","  calculator(empty_imgs)\n","  train_summary_writer, val_summary_writer = create_summary_writers(config_name=\"RUN1\")\n","  save_path = \"trained_model_RUN1\"\n","\n","  for optimizer in optimizers : \n","    training_loop(calculator, optimizer, n_epochs, \n","            train, val, \n","            train_summary_writer, val_summary_writer, \n","            save_path)\n","    \n","  if (task == \"calc\") : pass \n","  elif (task == \"comp\") : pass"],"metadata":{"id":"ndCPRSl-TOLz","executionInfo":{"status":"ok","timestamp":1669674139041,"user_tz":-60,"elapsed":193,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["calculator = MNISTCalc()\n","list_optimizers = ['Adam'] #['Adam', 'SGD']\n","\n","training(list_optimizers, 100, task=\"calc\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":744},"id":"NGJ-QiK2ThzV","executionInfo":{"status":"error","timestamp":1669674178579,"user_tz":-60,"elapsed":37873,"user":{"displayName":"Jakob L","userId":"16423787364056091927"}},"outputId":"f8b2676b-1999-4624-be5e-7e3d04d61b0c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0:\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1875/1875 [00:35<00:00, 52.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["['binary_accuracy: 0.09003333002328873', 'loss: 15.382424354553223']\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-dccef3822062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlist_optimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#['Adam', 'SGD']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_optimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"calc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-f9305146f40b>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(optimizers, n_epochs, task)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_summary_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             save_path)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"calc\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-52ee7f76f017>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, optimizer, n_epochs, train, test, train_summary_writer, val_summary_writer, save_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# 5. evaluate on validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m# 6. log validation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mval_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1495\u001b[0m       \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0mare\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \"\"\"\n\u001b[0;32m-> 1497\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36munpack_x_y_sample_weight\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     error_msg = (\"Data is expected to be in format `x`, `(x,)`, `(x, y)`, \"\n\u001b[1;32m   1578\u001b[0m                  \"or `(x, y, sample_weight)`, found: {}\").format(data)\n\u001b[0;32m-> 1579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<tf.Tensor: shape=(32, 784), dtype=float32, numpy=\narray([[-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.],\n       ...,\n       [-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.]], dtype=float32)>, <tf.Tensor: shape=(32, 784), dtype=float32, numpy=\narray([[-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.],\n       ...,\n       [-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.],\n       [-1., -1., -1., ..., -1., -1., -1.]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\narray([ 2, -4, -1,  6,  2, -8,  7,  6, -2, -2,  1, -7, -2, -1,  4, -4, -4,\n        7, -5, -6,  5, -1,  2,  1,  3, -2, -1,  0,  0,  3,  6,  2],\n      dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 0], dtype=int32)>)"]}]}]}